{
  "non_violating_objects_bounding_boxes": "{'Brown box on the left, sat on a pallet': '[x: 0.54048684\\ny: 0.31195335\\n, x: 0.9633383\\ny: 1.0\\n]', 'box atop a pallet': '[x: 0.53368063\\ny: 0.39915074\\n, x: 0.93654584\\ny: 0.92144374\\n]', 'box on pallet right side of image': '[x: 0.59355037\\ny: 0.41714286\\n, x: 0.93316712\\ny: 0.89714286\\n]', 'Pallet, on right side of image, carboard box resting on top of it': '[x: 0.52887623\\ny: 0.74204947\\n, x: 0.93919699\\ny: 0.93626778\\n]', 'Carboard box, resting on pallet, on right side of image': '[x: 0.58912237\\ny: 0.42008578\\n, x: 0.8881323\\ny: 0.80729251\\n]'}",
  "prompt": "You must adhere to the the following constraints <CONSTRAINTS START> Robot's Rules: My end-effector is a miniature forklift. I can only lift objects that have pallet-like openings or are resting on a pallet.<CONSTRAINTS END> \nPoint to all objects you can interface with.in the given image <1>. Assign very short descriptive natural language labels to objects in output. The answer should follow the json format: [{\"point\": <point>, \"label\": <label1>}, ...]. The points are in [y, x] format normalized to 0-1000. Any rationale or explanation can be prepended to the json output",
  "violating_objects_bounding_boxes": "{'cardboard box to the left of the image': '[x: 0.14322817\\ny: 0.50434295\\n, x: 0.45260102\\ny: 0.9141216\\n]', 'Brown box on the left ': '[x: 0.10815074\\ny: 0.4214876\\n, x: 0.47616366\\ny: 0.95592287\\n]', 'box sitting on the floor': '[x: 0.14325375\\ny: 0.49083503\\n, x: 0.45197113\\ny: 0.90020367\\n]', 'box on floor, left side of image': '[x: 0.14736764\\ny: 0.47567568\\n, x: 0.45094499\\ny: 0.90810811\\n]', 'Cardboard box, resting on wooden surface, left side of image': '[x: 0.14515228\\ny: 0.48122867\\n, x: 0.44755285\\ny: 0.91638225\\n]'}"
}